{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1598079026364",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklean的学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入包\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(0, 1)\t1.0\n  (0, 3)\t100.0\n  (1, 0)\t1.0\n  (1, 3)\t60.0\n  (2, 2)\t1.0\n  (2, 3)\t30.0\n"
    }
   ],
   "source": [
    "#字典实例化抽取\n",
    "dict = DictVectorizer()\n",
    "#调用fit_transform\n",
    "data = dict.fit_transform([{'city': '北京', 'temperature': 100},{'city': '上海', 'temperature': 60},{'city': '深圳', 'temperature': 30}])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[  0.   1.   0. 100.]\n [  1.   0.   0.  60.]\n [  0.   0.   1.  30.]]\n"
    }
   ],
   "source": [
    "#字典实例化抽取\n",
    "dict = DictVectorizer(sparse=False)\n",
    "#调用fit_transform\n",
    "data = dict.fit_transform([{'city': '北京', 'temperature': 100},{'city': '上海', 'temperature': 60},{'city': '深圳', 'temperature': 30}])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sparse矩阵将数组中为0的省略输出，有值的进行提取输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[{'city': '北京', 'temperature': 100}, {'city': '上海', 'temperature': 60}, {'city': '深圳', 'temperature': 30}]\n"
    }
   ],
   "source": [
    "origin_data=[{'city': '北京', 'temperature': 100},{'city': '上海', 'temperature': 60},{'city': '深圳', 'temperature': 30}]\n",
    "print(origin_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['city=上海', 'city=北京', 'city=深圳', 'temperature']\n[[  0.   1.   0. 100.]\n [  1.   0.   0.  60.]\n [  0.   0.   1.  30.]]\n"
    }
   ],
   "source": [
    "#字典实例化抽取\n",
    "dict = DictVectorizer(sparse=False)\n",
    "#调用fit_transform\n",
    "data = dict.fit_transform([{'city': '北京', 'temperature': 100},{'city': '上海', 'temperature': 60},{'city': '深圳', 'temperature': 30}])\n",
    "print(dict.get_feature_names())\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "字典数据抽取：将同类别的转化为1，不同类别的置为0,数值类型的数据不进行转化  \n",
    "目的：转化为one-hot编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[{'city=北京': 1.0, 'temperature': 100.0}, {'city=上海': 1.0, 'temperature': 60.0}, {'city=深圳': 1.0, 'temperature': 30.0}]\n"
    }
   ],
   "source": [
    "#字典实例化抽取\n",
    "dict = DictVectorizer(sparse=False)\n",
    "#调用fit_transform\n",
    "data = dict.fit_transform([{'city': '北京', 'temperature': 100},{'city': '上海', 'temperature': 60},{'city': '深圳', 'temperature': 30}])\n",
    "#inverse_transform(data):将数据回转\n",
    "print(dict.inverse_transform(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对文本数据进行特征值化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['dislike', 'is', 'life', 'long', 'love', 'python', 'short', 'too']\n[[0 1 1 0 1 1 1 0]\n [1 1 1 1 0 1 0 1]]\n"
    }
   ],
   "source": [
    "cv=CountVectorizer()\n",
    "data=cv.fit_transform(['life is short,i love python','life is too long,i dislike python'])\n",
    "print(cv.get_feature_names()) #统计文章\n",
    "print(data.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文本特征抽取:  \n",
    "* 统计文章中所有的词，重复的只统计一次  \n",
    "* 对每篇文章，在词列表里面统计每个词出现的**次数**\n",
    "* 单个字母不统计  \n",
    "\n",
    "用处:  \n",
    "* 文本分类  \n",
    "* 情感分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['不用python', '人生漫长', '人生苦短', '我用python']\n[[0 0 1 1]\n [1 1 0 0]]\n"
    }
   ],
   "source": [
    "cv=CountVectorizer()\n",
    "data=cv.fit_transform(['人生苦短，我用python','人生漫长，不用python'])\n",
    "print(cv.get_feature_names()) #统计文章\n",
    "print(data.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['python', '不用', '人生', '漫长', '苦短']\n[[1 0 1 0 1]\n [1 1 1 1 0]]\n"
    }
   ],
   "source": [
    "cv=CountVectorizer()\n",
    "data=cv.fit_transform(['人生 苦短，我 用 python','人生 漫长，不用 python'])\n",
    "print(cv.get_feature_names()) #统计文章\n",
    "print(data.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 中文特征值化\n",
    "对于中文，要先进行分词处理\n",
    "* jieba模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<generator object Tokenizer.cut at 0x000001BED99FEC10>"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "#返回的是一个词语生成器\n",
    "jieba.cut('我是一个好程序员')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<generator object Tokenizer.cut at 0x0000025F40FDF350>\n<generator object Tokenizer.cut at 0x0000025F40FDF430>\n<generator object Tokenizer.cut at 0x0000025F40FDF660>\n"
    }
   ],
   "source": [
    "con1=jieba.cut('今天很残酷，明天更残酷，后天很美好，但绝对大部分是死在明天晚上，所以每个人不要放弃今天。')\n",
    "\n",
    "con2=jieba.cut('我们看到的从很远星系来的光是在几百万年之前发出的，这样当我们看到宇宙时，我们是在看它的过去。')\n",
    "\n",
    "con3=jieba.cut('如果只用一种方式了解某样事物，你就不会真正了解它。了解事物真正含义的秘密取决于如何将其与我们所了解的事物相联系。')\n",
    "\n",
    "print(con1)\n",
    "print(con2)\n",
    "print(con3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Building prefix dict from the default dictionary ...\nLoading model from cache C:\\Users\\17575\\AppData\\Local\\Temp\\jieba.cache\nLoading model cost 0.564 seconds.\nPrefix dict has been built successfully.\n今天 很 残酷 ， 明天 更 残酷 ， 后天 很 美好 ， 但 绝对 大部分 是 死 在 明天 晚上 ， 所以 每个 人 不要 放弃 今天 。\n****************************************************************************************************\n我们 看到 的 从 很 远 星系 来 的 光是在 几百万年 之前 发出 的 ， 这样 当 我们 看到 宇宙 时 ， 我们 是 在 看 它 的 过去 。\n****************************************************************************************************\n如果 只用 一种 方式 了解 某样 事物 ， 你 就 不会 真正 了解 它 。 了解 事物 真正 含义 的 秘密 取决于 如何 将 其 与 我们 所 了解 的 事物 相 联系 。\n"
    }
   ],
   "source": [
    "#转换为列表\n",
    "content1=list(con1)\n",
    "content2=list(con2)\n",
    "content3=list(con3)\n",
    "\n",
    "#把列表转化为字符串\n",
    "c1=' '.join(content1)\n",
    "c2=' '.join(content2)\n",
    "c3=' '.join(content3)\n",
    "\n",
    "print(c1)\n",
    "print('*'*100)\n",
    "print(c2)\n",
    "print('*'*100)\n",
    "print(c3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['一种', '不会', '不要', '之前', '了解', '事物', '今天', '光是在', '几百万年', '发出', '取决于', '只用', '后天', '含义', '大部分', '如何', '如果', '宇宙', '我们', '所以', '放弃', '方式', '明天', '星系', '晚上', '某样', '残酷', '每个', '看到', '真正', '秘密', '绝对', '美好', '联系', '过去', '这样']\n[[0 0 1 0 0 0 2 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 2 0 1 0 2 1 0 0 0 1 1 0 0 0]\n [0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 3 0 0 0 0 1 0 0 0 0 2 0 0 0 0 0 1 1]\n [1 1 0 0 4 3 0 0 0 0 1 1 0 1 0 1 1 0 1 0 0 1 0 0 0 1 0 0 0 2 1 0 0 1 0 0]]\n"
    }
   ],
   "source": [
    "cv=CountVectorizer()\n",
    "data=cv.fit_transform([c1,c2,c3])\n",
    "print(cv.get_feature_names()) #统计文章\n",
    "print(data.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文本分类tf idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* tf:词的频率(**出现的次数**)  \n",
    "* idf：逆文档频率(log(**总文档数量/该词出现的频率**))  \n",
    "* 重要程度：tf*idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['一种', '不会', '不要', '之前', '了解', '事物', '今天', '光是在', '几百万年', '发出', '取决于', '只用', '后天', '含义', '大部分', '如何', '如果', '宇宙', '我们', '所以', '放弃', '方式', '明天', '星系', '晚上', '某样', '残酷', '每个', '看到', '真正', '秘密', '绝对', '美好', '联系', '过去', '这样']\n[[0.         0.         0.21821789 0.         0.         0.\n  0.43643578 0.         0.         0.         0.         0.\n  0.21821789 0.         0.21821789 0.         0.         0.\n  0.         0.21821789 0.21821789 0.         0.43643578 0.\n  0.21821789 0.         0.43643578 0.21821789 0.         0.\n  0.         0.21821789 0.21821789 0.         0.         0.        ]\n [0.         0.         0.         0.2410822  0.         0.\n  0.         0.2410822  0.2410822  0.2410822  0.         0.\n  0.         0.         0.         0.         0.         0.2410822\n  0.55004769 0.         0.         0.         0.         0.2410822\n  0.         0.         0.         0.         0.48216441 0.\n  0.         0.         0.         0.         0.2410822  0.2410822 ]\n [0.15698297 0.15698297 0.         0.         0.62793188 0.47094891\n  0.         0.         0.         0.         0.15698297 0.15698297\n  0.         0.15698297 0.         0.15698297 0.15698297 0.\n  0.1193896  0.         0.         0.15698297 0.         0.\n  0.         0.15698297 0.         0.         0.         0.31396594\n  0.15698297 0.         0.         0.15698297 0.         0.        ]]\n"
    }
   ],
   "source": [
    "cv=TfidfVectorizer()\n",
    "data=cv.fit_transform([c1,c2,c3])\n",
    "print(cv.get_feature_names()) #统计文章\n",
    "print(data.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面矩阵代表了词的重要性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}